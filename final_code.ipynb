{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f866959a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import cvzone\n",
    "from cvzone.FaceMeshModule import FaceMeshDetector\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import dlib\n",
    "from imutils import face_utils\n",
    "from pygame import mixer\n",
    "from scipy.spatial import distance as dist\n",
    "import mediapipe as mp\n",
    "import re\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split , GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, classification_report , accuracy_score\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0ba4ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from playsound import playsound\n",
    "# for playing wav file\n",
    "\n",
    "def alert():\n",
    "    play = playsound(\"C:/Users/kadem/cdsaml/alert_alarm.wav\")\n",
    "\n",
    "\n",
    "def eye_aspect_ratio(eye):\n",
    "    p2_minus_p6 = dist.euclidean(eye[1], eye[5])\n",
    "    p3_minus_p5 = dist.euclidean(eye[2], eye[4])\n",
    "    p1_minus_p4 = dist.euclidean(eye[0], eye[3])\n",
    "    ear = (p2_minus_p6 + p3_minus_p5) / (2.0 * p1_minus_p4)\n",
    "    return ear\n",
    "\n",
    "def mouth_aspect_ratio(mouth):\n",
    "\t# compute the euclidean distances between the two sets of\n",
    "\t# vertical mouth landmarks (x, y)-coordinates\n",
    "    A = dist.euclidean(mouth[2], mouth[10]) # 51, 59\n",
    "    B = dist.euclidean(mouth[4], mouth[8]) # 53, 57\n",
    "\n",
    "\t# compute the euclidean distance between the horizontal\n",
    "\t# mouth landmark (x, y)-coordinates\n",
    "    C = dist.euclidean(mouth[0], mouth[6]) # 49, 55\n",
    "\n",
    "\t# compute the mouth aspect ratio\n",
    "    mar = (A + B) / (2.0 * C)\n",
    "\n",
    "\t# return the mouth aspect ratio\n",
    "    return mar\n",
    "\n",
    "\n",
    "# FACIAL_LANDMARKS_IDXS = OrderedDict([\n",
    "# \t(\"mouth\", (48, 68)),\n",
    "# \t(\"right_eyebrow\", (17, 22)),\n",
    "# \t(\"left_eyebrow\", (22, 27)),\n",
    "# \t(\"right_eye\", (36, 42)),\n",
    "# \t(\"left_eye\", (42, 48)),\n",
    "# \t(\"nose\", (27, 35)),\n",
    "# \t(\"jaw\", (0, 17))\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43ee7a6e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Defining threshold to classify whether the person is drowsy or not\n",
    "\n",
    "MOUTH_AR_THRESH = 0.5\n",
    "EAR_AR_THRESH = 0.2\n",
    "mouth_count = 0\n",
    "eye_count = 0\n",
    "thresh_count = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5faa588b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.31491987600322535\n",
      "0.28777605935203765\n",
      "0.29773719145970895\n",
      "0.291540239825968\n",
      "0.28187289335485466\n",
      "0.2870043122313309\n",
      "0.2832478029400136\n",
      "0.22318749619230746\n",
      "0.22221480447053799\n",
      "0.26163187412843625\n",
      "0.26122298275594996\n",
      "0.2620850924465564\n",
      "0.26759727859278337\n",
      "0.2778865708145333\n",
      "0.2553116728289208\n",
      "0.24445236675984408\n",
      "0.2242627793972226\n",
      "0.20609218247385913\n",
      "0.185113803722196\n",
      "0.20123783335606044\n",
      "0.18826950066420914\n",
      "0.1817609383510348\n",
      "0.178498436547312\n",
      "0.2111250211773697\n",
      "0.18289765057561397\n",
      "0.19990099168865305\n",
      "0.29274096308572906\n",
      "0.29280203208778105\n",
      "0.291489962859524\n",
      "0.2989268132152749\n",
      "0.2921739130434783\n",
      "0.2978808195361129\n",
      "0.28090567331957284\n",
      "0.3105593287120122\n",
      "0.30288959103615104\n",
      "0.2811709788979976\n",
      "0.3102787284449374\n",
      "0.2984768393895746\n",
      "0.29897904331195957\n",
      "0.29220007311702645\n",
      "0.2919184191881248\n",
      "0.2915844239621318\n",
      "0.3057318680939508\n",
      "0.3054404754837641\n",
      "0.2607731265928682\n",
      "0.22865331747512965\n",
      "0.20439162353230017\n",
      "0.18751564297708154\n",
      "0.22385152623118565\n",
      "0.19884991198104654\n",
      "0.24723298224649276\n",
      "0.2724503830860604\n",
      "0.2562309078385043\n",
      "0.2492432991143828\n",
      "0.24749917642614502\n",
      "0.26818733965986563\n",
      "0.24533146658254035\n",
      "0.27690795763976317\n",
      "0.27782996999311566\n",
      "0.24615843057874254\n",
      "0.2675361339214928\n",
      "0.2418892326915807\n",
      "0.24338243331128176\n",
      "0.27296322274784224\n",
      "0.20433447413392491\n",
      "0.1990717856425414\n",
      "0.2440180863566121\n",
      "0.21901808635661213\n",
      "0.20925563774800904\n",
      "0.17948025522283362\n",
      "0.220730827113577\n",
      "0.1871670237377795\n",
      "0.2101397347538858\n",
      "0.19527887913329078\n",
      "0.2834910787828666\n",
      "0.2651953949484219\n",
      "0.2698151976688047\n",
      "0.26529927031458933\n",
      "0.2752257143778776\n",
      "0.2657529964410623\n",
      "0.2819427260187043\n",
      "0.1985211469757284\n",
      "0.1857319759321212\n",
      "0.20289684308956346\n",
      "0.18651082109308803\n",
      "0.24456821978060994\n",
      "0.24456821978060994\n"
     ]
    }
   ],
   "source": [
    "video_capture= cv2.VideoCapture(0)\n",
    "detector=FaceMeshDetector()\n",
    "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "detect = dlib.get_frontal_face_detector()\n",
    "(leftEyeStart, leftEyeEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"left_eye\"]\n",
    "(rightEyeStart, rightEyeEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"right_eye\"]\n",
    "(mouthStart,mouthEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"mouth\"]\n",
    "\n",
    "list_df = []\n",
    "\n",
    "while True:\n",
    "        _,frame = video_capture.read()      \n",
    "        modelFile = \"res10_300x300_ssd_iter_140000.caffemodel\"\n",
    "        configFile = \"deploy.prototxt.txt\"\n",
    "        net = cv2.dnn.readNetFromCaffe(configFile, modelFile)\n",
    "        h, w = frame.shape[:2]\n",
    "        blob = cv2.dnn.blobFromImage(cv2.resize(frame, (300, 300)), 1.0,(300, 300), (104.0, 117.0, 123.0))\n",
    "        net.setInput(blob)\n",
    "        faces = net.forward()\n",
    "        for i in range(faces.shape[2]):\n",
    "            confidence = faces[0, 0, i, 2]\n",
    "            if confidence > 0.5:\n",
    "                    box = faces[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "                    (x, y, x1, y1) = box.astype(\"int\")\n",
    "                    cv2.rectangle(frame, (x, y), (x1, y1), (0, 0, 255), 2)\n",
    "\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = detect(gray)\n",
    "        area = lambda x,y,w,h:(w-x)*(h-y)\n",
    "        f = -1\n",
    "        if len(faces):\n",
    "            for face in faces:\n",
    "                x = face.left()\n",
    "                y = face.top()\n",
    "                w = face.right()\n",
    "                h = face.bottom()\n",
    "                my_area =  area(x,y,w,h)\n",
    "                if(my_area>f):\n",
    "                    f = my_area\n",
    "                    face1 = face       \n",
    "                    landmarks = predictor(gray, face1)\n",
    "                    landmarks = face_utils.shape_to_np(landmarks)\n",
    "                        \n",
    "\n",
    "#         for n in range(0, 68):\n",
    "#             (x,y) = landmarks[n]\n",
    "#             cv2.circle(frame, (x, y), 1, (255, 255, 255), -1)\n",
    "\n",
    "            leftEye = landmarks[leftEyeStart:leftEyeEnd]\n",
    "            rightEye = landmarks[rightEyeStart:rightEyeEnd]\n",
    "        \n",
    "            mouth = landmarks[mouthStart:mouthEnd]\n",
    "            leftEAR = eye_aspect_ratio(leftEye)\n",
    "            rightEAR = eye_aspect_ratio(rightEye)\n",
    "\n",
    "            ear = (leftEAR + rightEAR) / 2.0\n",
    "            print(ear)\n",
    "            leftEyeHull = cv2.convexHull(leftEye)\n",
    "            rightEyeHull = cv2.convexHull(rightEye)\n",
    "            cv2.drawContours(frame, [leftEyeHull], -1, (0, 255, 0), 1)\n",
    "            cv2.drawContours(frame, [rightEyeHull], -1, (0, 255, 0), 1)\n",
    "            mouthMAR = mouth_aspect_ratio(mouth)\n",
    "            mar = mouthMAR\n",
    "\n",
    "            mouthHull = cv2.convexHull(mouth)\n",
    "            cv2.drawContours(frame, [mouthHull], -1, (0, 255, 0), 1)\n",
    "            cv2.putText(frame, \"MAR: {:.2f}\".format(mar), (30, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2,cv2.LINE_AA,False)\n",
    "            cv2.putText(frame, \"EAR: {:.2f}\".format(ear), (30, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2,cv2.LINE_AA,False)\n",
    "        \n",
    "            if mar > MOUTH_AR_THRESH and mouth_count < thresh_count:\n",
    "                mouth_count += 1\n",
    "                cv2.putText(frame, \"Mouth is Open!\", (200,30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,128,255),2)\n",
    "                #cv2.putText(frame, \"MAR: {:.2f}\".format(mar), (60, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2,cv2.LINE_AA,False)\n",
    "            \n",
    "            elif mar > MOUTH_AR_THRESH and mouth_count >= thresh_count:\n",
    "                alert()\n",
    "                list_df.append(['Drowsy',ear,mar])\n",
    "                mouth_count = 0\n",
    "                cv2.putText(frame, \"Drowsy!!\", (200,30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,128,255),2)\n",
    "            \n",
    "            if ear < EAR_AR_THRESH and eye_count < thresh_count:\n",
    "                cv2.putText(frame, \"Eye is closed!\", (200,60),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,128,255),2)\n",
    "                eye_count += 1\n",
    "                \n",
    "            \n",
    "            elif ear< EAR_AR_THRESH and eye_count >= thresh_count:\n",
    "                alert()\n",
    "                cv2.putText(frame, \"Sleepy!\", (200,60),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,128,255),2)\n",
    "                list_df.append(['Sleepy',ear,mar])\n",
    "                eye_count = 0\n",
    "                \n",
    "                \n",
    "            \n",
    "        cv2.imshow('Video',frame)\n",
    "        cv2.waitKey(1)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "            \n",
    "\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "156b2fe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>EAR</th>\n",
       "      <th>MAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sleepy</td>\n",
       "      <td>0.199901</td>\n",
       "      <td>0.377756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sleepy</td>\n",
       "      <td>0.195279</td>\n",
       "      <td>0.426497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Drowsy</td>\n",
       "      <td>0.244568</td>\n",
       "      <td>0.500108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    State       EAR       MAR\n",
       "0  Sleepy  0.199901  0.377756\n",
       "1  Sleepy  0.195279  0.426497\n",
       "2  Drowsy  0.244568  0.500108"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Writing state, ear, mar into csv\n",
    "\n",
    "df = pd.DataFrame(list_df,columns = ['State','EAR','MAR'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14d562ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EAR</th>\n",
       "      <th>MAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.213249</td>\n",
       "      <td>0.434787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.027221</td>\n",
       "      <td>0.061596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.195279</td>\n",
       "      <td>0.377756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.197590</td>\n",
       "      <td>0.402126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.199901</td>\n",
       "      <td>0.426497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.222235</td>\n",
       "      <td>0.463302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.244568</td>\n",
       "      <td>0.500108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            EAR       MAR\n",
       "count  3.000000  3.000000\n",
       "mean   0.213249  0.434787\n",
       "std    0.027221  0.061596\n",
       "min    0.195279  0.377756\n",
       "25%    0.197590  0.402126\n",
       "50%    0.199901  0.426497\n",
       "75%    0.222235  0.463302\n",
       "max    0.244568  0.500108"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a3766e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
